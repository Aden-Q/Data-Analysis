{"cells":[{"metadata":{"_uuid":"10efec83-f01d-4417-ba1a-09e605e00675","_cell_guid":"044f54b5-e1bb-4f5f-85ac-469e52e6dde3","trusted":true},"cell_type":"markdown","source":"# File Processing"},{"metadata":{"_uuid":"25c0c02d-7d0f-4070-a14a-67a1b0e44a92","_cell_guid":"e4f963cb-4fa9-4ea9-9589-1158f25f60b4","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"e8950c80-15a6-4595-b252-58350e2e3ba4","_cell_guid":"809f6e27-e99f-41e1-a5b0-d88e36e56861","trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/denoising-dirty-documents/train.zip > /dev/null\n!unzip /kaggle/input/denoising-dirty-documents/train_cleaned.zip > /dev/null\n!unzip /kaggle/input/denoising-dirty-documents/sampleSubmission.csv.zip > /dev/null\n!unzip /kaggle/input/denoising-dirty-documents/test.zip > /dev/null","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"5599152c-df21-43f5-b8f1-f0f6ca0db151","_cell_guid":"92124734-38c4-4403-920c-bb909e4d9e50","trusted":true},"cell_type":"code","source":"!ls","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"41ab1525-2cd6-40da-a24e-37cd75b04291","_cell_guid":"8ae1df07-f14c-4a96-b8da-b7a06b7cd877","trusted":true},"cell_type":"markdown","source":"# Import Modules"},{"metadata":{"_uuid":"d558e3f4-63b5-4458-832f-c966fe258ba4","_cell_guid":"d6b716ff-1378-439b-ab94-d934a36eb13f","trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam, RMSprop, Adagrad, Adadelta\nfrom sklearn.model_selection import train_test_split\nimport os\nimport cv2\nimport matplotlib.pyplot as plt","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"64fc23fb-cffd-4fb7-88d9-c7e980c4a437","_cell_guid":"d4d6468b-8482-422f-9464-180e3b16af48","trusted":true},"cell_type":"code","source":"df = pd.read_csv('sampleSubmission.csv')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"046110fb-ba39-485c-b2df-26f857ace925","_cell_guid":"a4176679-c985-4310-97ba-e68c24ed8020","trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"269f0103-30a5-4e41-95d3-c7334bbe7eea","_cell_guid":"d85809fb-e4f4-484f-ac86-d9e99e823f84","trusted":true},"cell_type":"code","source":"img = cv2.imread('train/167.png', 0)\nplt.imshow(img, cmap=\"gray\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c62f0457-ec5b-4403-bbab-ce58e656e9e3","_cell_guid":"a019f32a-2b1f-40db-92d7-0aee2d4da08b","trusted":true},"cell_type":"code","source":"img.shape","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"918fa20e-e7d4-4e2a-879a-94a9fcc92184","_cell_guid":"615d2354-de37-410c-b3bc-020db400fcbb","trusted":true},"cell_type":"code","source":"img = cv2.imread('train_cleaned/101.png', 0)\nplt.imshow(img, cmap=\"gray\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9221f8b4-fc40-4a98-ac5a-bec6596c475b","_cell_guid":"8b9d49e2-623b-4221-9cf9-85a1381f86c3","trusted":true},"cell_type":"markdown","source":"# Load Dataset"},{"metadata":{"_uuid":"a3dbb902-1571-4603-86f0-9888f163dd70","_cell_guid":"44435b8b-cf80-4bf0-854d-0e1067520368","trusted":true},"cell_type":"code","source":"img_w, img_h = (258, 540)\nprint('Image height: ', img_h)\nprint('Image width: ', img_w)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"119db85d-fc70-4cdc-a4a9-0b087a6ad9b7","_cell_guid":"5e7805b1-ab9b-4cb9-8408-f9a623526dca","trusted":true},"cell_type":"code","source":"def load_images(path):\n    '''Read in all the images under the directory specified by path\n    '''\n    filename_list = os.listdir(path)\n    num_files = len(filename_list)\n    imgs = np.zeros((num_files, img_w, img_h, 1))\n    idx = 0\n    \n    for filename in filename_list:\n        file_path = path + filename\n        img = cv2.imread(file_path, 0)\n        img.resize(img_w, img_h, 1)\n        imgs[idx] = img\n        idx += 1\n        \n    return imgs","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"0b05ff25-def6-49a4-9c7a-8ee0add9566a","_cell_guid":"8d2807a3-6fdc-4d34-a5c5-8e70fe1b4b58","trusted":true},"cell_type":"code","source":"x_train = load_images('./train/')\nx_train_cleaned = load_images('./train_cleaned/')\nx_test = load_images('./test/')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"639b0acd-2624-4d7a-ab95-d50c90d4299f","_cell_guid":"d3bce6c2-42c7-45f7-ac49-bee6a546d6dd","trusted":true},"cell_type":"code","source":"print('Number of train images: ', len(x_train))\nprint('Number of train cleaned images: ', len(x_train_cleaned))\nprint('Number of test images: ', len(x_test))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"979fab93-a416-4004-98a5-2fb07acf7f02","_cell_guid":"d8453930-f416-46ff-aa76-a61a6c224dbd","trusted":true},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_uuid":"d65cd198-c054-496b-852c-85334a6c08df","_cell_guid":"b3a0bc5b-8ed3-4a42-8425-d72c3085805d","trusted":true},"cell_type":"code","source":"def normalization(imgs):\n    return imgs / 255.0","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9cacc296-bc95-4784-b87b-2fceba3e57f8","_cell_guid":"3a780c7c-4c75-4fc1-be2c-278f456daf52","trusted":true},"cell_type":"code","source":"# Apply max normalization to all data points\nx_train = normalization(x_train)\nx_train_cleaned = normalization(x_train_cleaned)\nx_test = normalization(x_test)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ef5afa77-1cbc-4473-930a-777044efb56d","_cell_guid":"cb4c5dee-59d8-4629-8a5c-fae728fee8ae","trusted":true},"cell_type":"markdown","source":"# Define Network Architecture"},{"metadata":{"_uuid":"04dc9128-c725-4f7c-9150-e14e089ff4b9","_cell_guid":"8790cd71-7dc6-4749-a2aa-3d9e4809f0a4","trusted":true},"cell_type":"code","source":"class Autoencoder():\n    def __init__(self, optimizer=Adam, lr=0.001):\n        self.img_width = img_w\n        self.img_height = img_h\n        self.img_channel = 1\n        self.optimizer = optimizer(learning_rate=lr)\n        self.lr= lr\n    \n    def build_model(self):\n        input_img = Input(shape=(self.img_width, self.img_height, self.img_channel)) # of shape (258, 540, 1)\n        # encoder\n        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n        x = MaxPooling2D((2, 2), padding='same')(x)\n        # x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n        # x = MaxPooling2D((2, 2), padding='same')(x)\n        # decoder\n        # x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n        # x = UpSampling2D((2, 2))(x)\n        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = UpSampling2D((2, 2))(x)\n        decoded_img = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n        \n        model = Model(input_img, decoded_img)\n        model.compile(optimizer=self.optimizer, loss='mse')\n        \n        return model","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"72680b76-d036-4d42-889e-ce009e4e3f59","_cell_guid":"7099093a-e88a-4ee6-8541-22afd57a5879","trusted":true},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"_uuid":"cdc8cb40-2af9-4fa9-80ee-e5352da5cd3e","_cell_guid":"d728dbf2-f57e-47c9-bfa8-fb406260fdfc","trusted":true},"cell_type":"code","source":"autoencoder = Autoencoder()\nmodel = autoencoder.build_model()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"33284bfc-0cad-48f7-ac3b-1351228c2e07","_cell_guid":"95a51532-b840-4ebb-9f52-81a270d04f97","trusted":true},"cell_type":"code","source":"history = model.fit(x_train, x_train_cleaned,\n                    batch_size=20,\n                    epochs=500,\n                    validation_split=0.15)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b605abae-af9a-4fda-b874-9538fdb5f1a7","_cell_guid":"c6590819-2998-435f-9622-59b54110de7f","trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.ylabel('Loss')\nplt.xlabel('Epoch')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"62cda3b2-36dd-48d1-8798-bdd0ace7a77d","_cell_guid":"47f23694-4d21-4e85-8366-8dc719c1b88e","trusted":true},"cell_type":"code","source":"result = model.predict(x_test)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"97948a90-2de6-4f8e-957e-ead492c03274","_cell_guid":"9994b955-4224-4895-ab09-f3c5da196b2a","trusted":true},"cell_type":"code","source":"plt.imshow(x_test[0], cmap=\"gray\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7a58abdd-e444-4390-b4ca-f45c3b5a146c","_cell_guid":"09eff2bb-9060-4155-b2f2-b45f5fbdf7cb","trusted":true},"cell_type":"code","source":"plt.imshow(result[0], cmap=\"gray\")","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"211171ab-2550-494c-aa2b-d33e0ee1ac6d","_cell_guid":"83ec11d0-0737-42fe-aae0-dc02799d9fbf","trusted":true},"cell_type":"markdown","source":"# Output File"},{"metadata":{"_uuid":"5397398a-5ff7-4348-9d60-4c062594ea39","_cell_guid":"9bf38a3c-a710-4e0c-8a90-695beeda32d7","trusted":true},"cell_type":"code","source":"ids = []\nvals = []\n\nfor filename in filename_list:\n    file_path = path + filename\n    img = cv2.imread(file_path, 0)\n    img.resize(img_w, img_h, 1)\n    imgs[idx] = img\n    idx += 1\n\npd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv', index=False)","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}